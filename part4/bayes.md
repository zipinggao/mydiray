## 朴素贝叶斯

###使用
假设有一手写数据集样本，共有100条记录，记录0-10是10个人各自写的0，记录11-20是10个人各自写的1,……..以此类推一共100条记录。那么这时候外头有个人进来写了个数字X，怎么识别出来它写的几呢？没学习过机器学习的人可能也能提出这样一种方法：我们只要把写的那个数字和0-9进行匹配，那个匹配度最高就是哪个数啦。没错，朴素贝叶斯用的就是这样朴素的思想（开玩笑，这里的朴素可不是这个意思）。

###算法介绍

朴素贝叶斯是基于贝叶斯定理与特征条件独立性假设的分类方法。对于给定的数据，基于特征条件独立性假设分别学习（联合概率分布）先验概率和条件概率，基于学习到的条件概率分布，对输入的$$x$$，求后验概率最大的输出$$y$$。

![](/assets/beyes1.png)


也就是说，只要我们知道$$P(X = x | Y= c_k),P(Y = c_k)$$和$$P(X= x)$$,就可以求出$$P(Y = c_k | X = x)$$的值。

朴素贝叶斯法的条件独立性假设：

![](/assets/beiyesi2.png)

每个类别的样本的各个特征之间是相互独立的，因此在计算的时候我们就可以将其拆成连乘的形式。由于这是一个较强的假设，朴素贝叶斯算法也由此得名。

**接下来求三个概率值：** $$P(X=x|Y=C_k)$$ ，$$P(Y=C_k)$$以及$$P(X = x)$$

(1)求$$P(X=x|Y=C_k)$$

![](/assets/beiyes3.png)

（2）求$$P(Y=C_k)$$

假设在训练集T中，类别为$$C_K$$的样本个数为$$N_k$$,在类别$$C_k$$的所有样本中$$X^{(j)} = x^{j}$$的样本个数为$$n_{jk}$$,那么:

![](/assets/beiyes4.png)

显而易见的$$P(X= x) = \frac{N_k}{N}$$,$$N$$为样本总数。

（3）求$$P(X = x)$$

![](/assets/beiyes5.png)

注意：当给定一个输入$$x$$,对于不同类别$$C_k$$,$$P(X = x)$$的值是相同，也就是说它的值不会影响我们对于输入实例属于某个类别的判定，因此我们只需设定：

$$P(X = x) = 1$$

**最终**:

![](/assets/beiyes6.png)


**综合理解**

![](/assets/beiye7.png)

往下转换：

![](/assets/beiyes8.png)

把$$P(X=x|Y=C_k)$$这一项变成了连乘，至于为什么能连乘，下图有详细说明:
![](/assets/beiye9.png)

比较$$Y$$为不同$$C_k$$的情况下哪个概率最大，那就表示属于哪个类的可能性最大。所以前头式子前头加上一个$$argmax$$，表示求让后式值最大的$$Ck$$。

![](/assets/beiys11.png)

上图中圈出来这一项是在$$Y$$为不同$$C_k$$情况下的连乘，所以不管$$k$$为多少，所有$$C_k$$连乘结果肯定是一致的，在比较谁的值最大时，式子里面的常数无法对结果的大小造成影响，可以去掉，结果如下：

![](/assets/beiye12.png)

###极大似然估计






